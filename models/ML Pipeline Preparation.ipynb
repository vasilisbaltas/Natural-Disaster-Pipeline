{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML Pipeline Preparation\n",
    "Follow the instructions below to help you create your ML pipeline.\n",
    "### 1. Import libraries and load data from database.\n",
    "- Import Python libraries\n",
    "- Load dataset from database with [`read_sql_table`](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.read_sql_table.html)\n",
    "- Define feature and target variables X and Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn==0.24.2 in /opt/conda/lib/python3.6/site-packages (0.24.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.6/site-packages (from scikit-learn==0.24.2) (3.1.0)\n",
      "Requirement already satisfied: joblib>=0.11 in /opt/conda/lib/python3.6/site-packages (from scikit-learn==0.24.2) (0.11)\n",
      "Requirement already satisfied: scipy>=0.19.1 in /opt/conda/lib/python3.6/site-packages (from scikit-learn==0.24.2) (1.2.1)\n",
      "Requirement already satisfied: numpy>=1.13.3 in /opt/conda/lib/python3.6/site-packages (from scikit-learn==0.24.2) (1.19.5)\n"
     ]
    }
   ],
   "source": [
    "!pip install scikit-learn==0.24.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The scikit-learn version is 0.19.1.\n"
     ]
    }
   ],
   "source": [
    "import sklearn\n",
    "print('The scikit-learn version is {}.'.format(sklearn.__version__))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "cannot import name '_safe_indexing'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-48-62510651a114>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mCustom_Transformers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mMessageTransformer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocessing\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mOneHotEncoder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompose\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mColumnTransformer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/sklearn/compose/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \"\"\"\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m from ._column_transformer import (ColumnTransformer, make_column_transformer,\n\u001b[0m\u001b[1;32m      9\u001b[0m                                   make_column_selector)\n\u001b[1;32m     10\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_target\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTransformedTargetRegressor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/sklearn/compose/_column_transformer.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocessing\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mFunctionTransformer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBunch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_safe_indexing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_get_column_indices\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_determine_key_type\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name '_safe_indexing'"
     ]
    }
   ],
   "source": [
    "# import libraries\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "import re\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from Custom_Transformers import MessageTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data from database\n",
    "engine = create_engine('sqlite:///Vasilis_db.db')\n",
    "df = pd.read_sql_table('Emergency_Messages', engine)\n",
    "df = df.drop(columns = ['id','original'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop rows with NaN messages\n",
    "df = df.dropna(subset=['message'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "message                    0\n",
       "genre                      0\n",
       "related                   32\n",
       "request                   32\n",
       "offer                     32\n",
       "aid_related               32\n",
       "medical_help              32\n",
       "medical_products          32\n",
       "search_and_rescue         32\n",
       "security                  32\n",
       "military                  32\n",
       "child_alone               32\n",
       "water                     32\n",
       "food                      32\n",
       "shelter                   32\n",
       "clothing                  32\n",
       "money                     32\n",
       "missing_people            32\n",
       "refugees                  32\n",
       "death                     32\n",
       "other_aid                 32\n",
       "infrastructure_related    32\n",
       "transport                 32\n",
       "buildings                 32\n",
       "electricity               32\n",
       "tools                     32\n",
       "hospitals                 32\n",
       "shops                     32\n",
       "aid_centers               32\n",
       "other_infrastructure      32\n",
       "weather_related           32\n",
       "floods                    32\n",
       "storm                     32\n",
       "fire                      32\n",
       "earthquake                32\n",
       "cold                      32\n",
       "other_weather             32\n",
       "direct_report             32\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# our dataset still contains some null values\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0    19879\n",
       "0.0     6111\n",
       "2.0      188\n",
       "Name: related, dtype: int64"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We can observe that the 'related' category also contains double's(2) that does not make sense - we will turn this 2s to 1s\n",
    "df.related.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df.related==2, 'related'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[['message','genre']]\n",
    "Y = df.drop(columns=['message','genre'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        direct\n",
       "1        direct\n",
       "2        direct\n",
       "3        direct\n",
       "4        direct\n",
       "5        direct\n",
       "6        direct\n",
       "7        direct\n",
       "8        direct\n",
       "9        direct\n",
       "10       direct\n",
       "11       direct\n",
       "12       direct\n",
       "13       direct\n",
       "14       direct\n",
       "15       direct\n",
       "16       direct\n",
       "17       direct\n",
       "18       direct\n",
       "19       direct\n",
       "20       direct\n",
       "21       direct\n",
       "22       direct\n",
       "23       direct\n",
       "24       direct\n",
       "25       direct\n",
       "26       direct\n",
       "27       direct\n",
       "28       direct\n",
       "29       direct\n",
       "          ...  \n",
       "26180      news\n",
       "26181      news\n",
       "26182      news\n",
       "26183      news\n",
       "26184      news\n",
       "26185      news\n",
       "26186      news\n",
       "26187      news\n",
       "26188      news\n",
       "26189      news\n",
       "26190      news\n",
       "26191      news\n",
       "26192      news\n",
       "26193      news\n",
       "26194      news\n",
       "26195      news\n",
       "26196      news\n",
       "26197      news\n",
       "26198      news\n",
       "26199      news\n",
       "26200      news\n",
       "26201      news\n",
       "26202      news\n",
       "26203      news\n",
       "26204      news\n",
       "26205      news\n",
       "26206      news\n",
       "26207      news\n",
       "26208      news\n",
       "26209      news\n",
       "Name: genre, Length: 26178, dtype: object"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.genre"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Write a tokenization function to process your text data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(text):\n",
    "    \"\"\" Function that tokenizes and lemmatizes text\n",
    "\n",
    "    :param text:     input text to be processed(str)\n",
    "    :return:         cleaned_tokens(str)\n",
    "    \"\"\"\n",
    "\n",
    "    stop_words = stopwords.words(\"english\")\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "    # Text normalization\n",
    "    text = re.sub(r\"[^a-zA-Z0-9]\", \" \", text.lower())\n",
    "    #tokenization\n",
    "    words = word_tokenize (text)\n",
    "    # lemmatization\n",
    "    cleaned_tokens = [lemmatizer.lemmatize(word).strip() for word in words if word not in stop_words]\n",
    "\n",
    "    return cleaned_tokens "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata: done\n",
      "Solving environment: | "
     ]
    }
   ],
   "source": [
    "#!conda install xgboost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Build a machine learning pipeline\n",
    "This machine pipeline should take in the `message` column as input and output classification results on the other 36 categories in the dataset. You may find the [MultiOutputClassifier](http://scikit-learn.org/stable/modules/generated/sklearn.multioutput.MultiOutputClassifier.html) helpful for predicting multiple target variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline([\n",
    "     ('vect', CountVectorizer(tokenizer=tokenize)),\n",
    "     ('tfidf', TfidfTransformer()),\n",
    "     ('clf', RandomForestClassifier(random_state=33))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ColumnTransformer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-45-91cb8dc8c71d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;34m(\u001b[0m\u001b[0;34m'onehot'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mOneHotEncoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle_unknown\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'ignore'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m ])\n\u001b[0;32m----> 7\u001b[0;31m preprocessor = ColumnTransformer([\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0;34m(\u001b[0m\u001b[0;34m'text'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext_transformer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;34m(\u001b[0m\u001b[0;34m'genre'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgenre_transformer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'ColumnTransformer' is not defined"
     ]
    }
   ],
   "source": [
    "text_transformer = Pipeline([\n",
    "    ('messagetransformer', MessageTransformer(tokenize)),\n",
    "])\n",
    "genre_transformer = Pipeline([\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('text', text_transformer, [0]),\n",
    "    ('genre', genre_transformer, [1])\n",
    "])\n",
    "pipeline_2 = Pipeline([\n",
    "    ('preprocess', preprocessor),\n",
    "    ('clf', RandomForestClassifier(random_state=33))\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Train pipeline\n",
    "- Split data into train and test sets\n",
    "- Train pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('vect', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "        strip...stimators=10, n_jobs=1,\n",
       "            oob_score=False, random_state=33, verbose=0, warm_start=False))])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, random_state=33)\n",
    "pipeline.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Test your model\n",
    "Report the f1 score, precision and recall for each output category of the dataset. You can do this by iterating through the columns and calling sklearn's `classification_report` on each."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = pipeline.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RELATED\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.32      0.20      0.24      1517\n",
      "        1.0       0.78      0.87      0.83      5028\n",
      "\n",
      "avg / total       0.68      0.72      0.69      6545\n",
      "\n",
      "REQUEST\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.84      0.97      0.90      5458\n",
      "        1.0       0.37      0.09      0.15      1087\n",
      "\n",
      "avg / total       0.76      0.82      0.78      6545\n",
      "\n",
      "OFFER\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        0.0       1.00      1.00      1.00      6513\n",
      "        1.0       0.00      0.00      0.00        32\n",
      "\n",
      "avg / total       0.99      1.00      0.99      6545\n",
      "\n",
      "AID_RELATED\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.59      0.84      0.69      3810\n",
      "        1.0       0.46      0.19      0.27      2735\n",
      "\n",
      "avg / total       0.54      0.57      0.52      6545\n",
      "\n",
      "MEDICAL_HELP\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.92      1.00      0.96      6006\n",
      "        1.0       0.00      0.00      0.00       539\n",
      "\n",
      "avg / total       0.84      0.92      0.88      6545\n",
      "\n",
      "MEDICAL_PRODUCTS\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.95      1.00      0.97      6194\n",
      "        1.0       0.00      0.00      0.00       351\n",
      "\n",
      "avg / total       0.90      0.95      0.92      6545\n",
      "\n",
      "SEARCH_AND_RESCUE\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.97      1.00      0.99      6377\n",
      "        1.0       0.00      0.00      0.00       168\n",
      "\n",
      "avg / total       0.95      0.97      0.96      6545\n",
      "\n",
      "SECURITY\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.98      1.00      0.99      6418\n",
      "        1.0       0.00      0.00      0.00       127\n",
      "\n",
      "avg / total       0.96      0.98      0.97      6545\n",
      "\n",
      "MILITARY\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.97      1.00      0.98      6327\n",
      "        1.0       1.00      0.00      0.01       218\n",
      "\n",
      "avg / total       0.97      0.97      0.95      6545\n",
      "\n",
      "CHILD_ALONE\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        0.0       1.00      1.00      1.00      6545\n",
      "\n",
      "avg / total       1.00      1.00      1.00      6545\n",
      "\n",
      "WATER\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.94      1.00      0.97      6131\n",
      "        1.0       0.00      0.00      0.00       414\n",
      "\n",
      "avg / total       0.88      0.94      0.91      6545\n",
      "\n",
      "FOOD\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.89      1.00      0.94      5801\n",
      "        1.0       0.37      0.01      0.02       744\n",
      "\n",
      "avg / total       0.83      0.89      0.83      6545\n",
      "\n",
      "SHELTER\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.91      1.00      0.95      5972\n",
      "        1.0       0.00      0.00      0.00       573\n",
      "\n",
      "avg / total       0.83      0.91      0.87      6545\n",
      "\n",
      "CLOTHING\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.98      1.00      0.99      6434\n",
      "        1.0       0.00      0.00      0.00       111\n",
      "\n",
      "avg / total       0.97      0.98      0.97      6545\n",
      "\n",
      "MONEY\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.97      1.00      0.99      6380\n",
      "        1.0       0.00      0.00      0.00       165\n",
      "\n",
      "avg / total       0.95      0.97      0.96      6545\n",
      "\n",
      "MISSING_PEOPLE\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.99      1.00      0.99      6477\n",
      "        1.0       0.00      0.00      0.00        68\n",
      "\n",
      "avg / total       0.98      0.99      0.98      6545\n",
      "\n",
      "REFUGEES\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.97      1.00      0.98      6329\n",
      "        1.0       0.00      0.00      0.00       216\n",
      "\n",
      "avg / total       0.94      0.97      0.95      6545\n",
      "\n",
      "DEATH\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.95      1.00      0.98      6250\n",
      "        1.0       0.00      0.00      0.00       295\n",
      "\n",
      "avg / total       0.91      0.95      0.93      6545\n",
      "\n",
      "OTHER_AID\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.87      0.99      0.93      5704\n",
      "        1.0       0.13      0.01      0.02       841\n",
      "\n",
      "avg / total       0.78      0.87      0.81      6545\n",
      "\n",
      "INFRASTRUCTURE_RELATED\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.94      1.00      0.97      6147\n",
      "        1.0       0.00      0.00      0.00       398\n",
      "\n",
      "avg / total       0.88      0.94      0.91      6545\n",
      "\n",
      "TRANSPORT\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.95      1.00      0.97      6218\n",
      "        1.0       0.00      0.00      0.00       327\n",
      "\n",
      "avg / total       0.90      0.95      0.93      6545\n",
      "\n",
      "BUILDINGS\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.95      1.00      0.97      6219\n",
      "        1.0       0.00      0.00      0.00       326\n",
      "\n",
      "avg / total       0.90      0.95      0.93      6545\n",
      "\n",
      "ELECTRICITY\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.98      1.00      0.99      6434\n",
      "        1.0       0.00      0.00      0.00       111\n",
      "\n",
      "avg / total       0.97      0.98      0.97      6545\n",
      "\n",
      "TOOLS\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.99      1.00      1.00      6500\n",
      "        1.0       0.00      0.00      0.00        45\n",
      "\n",
      "avg / total       0.99      0.99      0.99      6545\n",
      "\n",
      "HOSPITALS\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.99      1.00      0.99      6471\n",
      "        1.0       0.00      0.00      0.00        74\n",
      "\n",
      "avg / total       0.98      0.99      0.98      6545\n",
      "\n",
      "SHOPS\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        0.0       1.00      1.00      1.00      6515\n",
      "        1.0       0.00      0.00      0.00        30\n",
      "\n",
      "avg / total       0.99      1.00      0.99      6545\n",
      "\n",
      "AID_CENTERS\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.99      1.00      0.99      6464\n",
      "        1.0       0.00      0.00      0.00        81\n",
      "\n",
      "avg / total       0.98      0.99      0.98      6545\n",
      "\n",
      "OTHER_INFRASTRUCTURE\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.96      1.00      0.98      6297\n",
      "        1.0       0.00      0.00      0.00       248\n",
      "\n",
      "avg / total       0.93      0.96      0.94      6545\n",
      "\n",
      "WEATHER_RELATED\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.75      0.94      0.83      4745\n",
      "        1.0       0.50      0.15      0.24      1800\n",
      "\n",
      "avg / total       0.68      0.73      0.67      6545\n",
      "\n",
      "FLOODS\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.92      1.00      0.96      5994\n",
      "        1.0       0.25      0.01      0.01       551\n",
      "\n",
      "avg / total       0.86      0.91      0.88      6545\n",
      "\n",
      "STORM\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.91      0.99      0.95      5941\n",
      "        1.0       0.47      0.08      0.14       604\n",
      "\n",
      "avg / total       0.87      0.91      0.88      6545\n",
      "\n",
      "FIRE\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.99      1.00      0.99      6478\n",
      "        1.0       0.00      0.00      0.00        67\n",
      "\n",
      "avg / total       0.98      0.99      0.98      6545\n",
      "\n",
      "EARTHQUAKE\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.92      0.99      0.95      5911\n",
      "        1.0       0.75      0.17      0.28       634\n",
      "\n",
      "avg / total       0.90      0.91      0.89      6545\n",
      "\n",
      "COLD\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.98      1.00      0.99      6400\n",
      "        1.0       0.00      0.00      0.00       145\n",
      "\n",
      "avg / total       0.96      0.98      0.97      6545\n",
      "\n",
      "OTHER_WEATHER\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.95      1.00      0.98      6241\n",
      "        1.0       0.10      0.00      0.01       304\n",
      "\n",
      "avg / total       0.91      0.95      0.93      6545\n",
      "\n",
      "DIRECT_REPORT\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.82      0.97      0.89      5305\n",
      "        1.0       0.37      0.08      0.13      1240\n",
      "\n",
      "avg / total       0.73      0.80      0.74      6545\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "pred_cols = y_test.columns.tolist()\n",
    "for i,col in enumerate(pred_cols):\n",
    "     print(col.upper()+'\\n', classification_report(y_test[col].values, preds[:,i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Improve your model\n",
    "Use grid search to find better parameters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, error_score='raise',\n",
       "       estimator=Pipeline(memory=None,\n",
       "     steps=[('vect', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "        strip...stimators=10, n_jobs=1,\n",
       "            oob_score=False, random_state=33, verbose=0, warm_start=False))]),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid={'vect__ngram_range': ((1, 1), (1, 2)), 'clf__n_estimators': [50, 100, 200], 'clf__max_depth': [10, 20, None]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameters = {\n",
    "    'vect__ngram_range' : ((1, 1), (1, 2)),\n",
    "    'clf__n_estimators' :[50,100,200],\n",
    "    'clf__max_depth'        :[10,20,None]\n",
    "}\n",
    "\n",
    "cv = GridSearchCV(pipeline, param_grid=parameters, cv=3)\n",
    "cv.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Test your model\n",
    "Show the accuracy, precision, and recall of the tuned model.  \n",
    "\n",
    "Since this project focuses on code quality, process, and  pipelines, there is no minimum performance metric needed to pass. However, make sure to fine tune your models for accuracy, precision and recall to make your project stand out - especially for your portfolio!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RELATED\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.00      0.00      0.00      1517\n",
      "        1.0       0.77      1.00      0.87      5028\n",
      "\n",
      "avg / total       0.59      0.77      0.67      6545\n",
      "\n",
      "REQUEST\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.83      1.00      0.91      5458\n",
      "        1.0       0.00      0.00      0.00      1087\n",
      "\n",
      "avg / total       0.70      0.83      0.76      6545\n",
      "\n",
      "OFFER\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        0.0       1.00      1.00      1.00      6513\n",
      "        1.0       0.00      0.00      0.00        32\n",
      "\n",
      "avg / total       0.99      1.00      0.99      6545\n",
      "\n",
      "AID_RELATED\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.58      1.00      0.74      3810\n",
      "        1.0       0.00      0.00      0.00      2735\n",
      "\n",
      "avg / total       0.34      0.58      0.43      6545\n",
      "\n",
      "MEDICAL_HELP\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.92      1.00      0.96      6006\n",
      "        1.0       0.00      0.00      0.00       539\n",
      "\n",
      "avg / total       0.84      0.92      0.88      6545\n",
      "\n",
      "MEDICAL_PRODUCTS\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.95      1.00      0.97      6194\n",
      "        1.0       0.00      0.00      0.00       351\n",
      "\n",
      "avg / total       0.90      0.95      0.92      6545\n",
      "\n",
      "SEARCH_AND_RESCUE\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.97      1.00      0.99      6377\n",
      "        1.0       0.00      0.00      0.00       168\n",
      "\n",
      "avg / total       0.95      0.97      0.96      6545\n",
      "\n",
      "SECURITY\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.98      1.00      0.99      6418\n",
      "        1.0       0.00      0.00      0.00       127\n",
      "\n",
      "avg / total       0.96      0.98      0.97      6545\n",
      "\n",
      "MILITARY\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.97      1.00      0.98      6327\n",
      "        1.0       0.00      0.00      0.00       218\n",
      "\n",
      "avg / total       0.93      0.97      0.95      6545\n",
      "\n",
      "CHILD_ALONE\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        0.0       1.00      1.00      1.00      6545\n",
      "\n",
      "avg / total       1.00      1.00      1.00      6545\n",
      "\n",
      "WATER\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.94      1.00      0.97      6131\n",
      "        1.0       0.00      0.00      0.00       414\n",
      "\n",
      "avg / total       0.88      0.94      0.91      6545\n",
      "\n",
      "FOOD\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.89      1.00      0.94      5801\n",
      "        1.0       0.00      0.00      0.00       744\n",
      "\n",
      "avg / total       0.79      0.89      0.83      6545\n",
      "\n",
      "SHELTER\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.91      1.00      0.95      5972\n",
      "        1.0       0.00      0.00      0.00       573\n",
      "\n",
      "avg / total       0.83      0.91      0.87      6545\n",
      "\n",
      "CLOTHING\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.98      1.00      0.99      6434\n",
      "        1.0       0.00      0.00      0.00       111\n",
      "\n",
      "avg / total       0.97      0.98      0.97      6545\n",
      "\n",
      "MONEY\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.97      1.00      0.99      6380\n",
      "        1.0       0.00      0.00      0.00       165\n",
      "\n",
      "avg / total       0.95      0.97      0.96      6545\n",
      "\n",
      "MISSING_PEOPLE\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.99      1.00      0.99      6477\n",
      "        1.0       0.00      0.00      0.00        68\n",
      "\n",
      "avg / total       0.98      0.99      0.98      6545\n",
      "\n",
      "REFUGEES\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.97      1.00      0.98      6329\n",
      "        1.0       0.00      0.00      0.00       216\n",
      "\n",
      "avg / total       0.94      0.97      0.95      6545\n",
      "\n",
      "DEATH\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.95      1.00      0.98      6250\n",
      "        1.0       0.00      0.00      0.00       295\n",
      "\n",
      "avg / total       0.91      0.95      0.93      6545\n",
      "\n",
      "OTHER_AID\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.87      1.00      0.93      5704\n",
      "        1.0       0.00      0.00      0.00       841\n",
      "\n",
      "avg / total       0.76      0.87      0.81      6545\n",
      "\n",
      "INFRASTRUCTURE_RELATED\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.94      1.00      0.97      6147\n",
      "        1.0       0.00      0.00      0.00       398\n",
      "\n",
      "avg / total       0.88      0.94      0.91      6545\n",
      "\n",
      "TRANSPORT\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.95      1.00      0.97      6218\n",
      "        1.0       0.00      0.00      0.00       327\n",
      "\n",
      "avg / total       0.90      0.95      0.93      6545\n",
      "\n",
      "BUILDINGS\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.95      1.00      0.97      6219\n",
      "        1.0       0.00      0.00      0.00       326\n",
      "\n",
      "avg / total       0.90      0.95      0.93      6545\n",
      "\n",
      "ELECTRICITY\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.98      1.00      0.99      6434\n",
      "        1.0       0.00      0.00      0.00       111\n",
      "\n",
      "avg / total       0.97      0.98      0.97      6545\n",
      "\n",
      "TOOLS\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.99      1.00      1.00      6500\n",
      "        1.0       0.00      0.00      0.00        45\n",
      "\n",
      "avg / total       0.99      0.99      0.99      6545\n",
      "\n",
      "HOSPITALS\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.99      1.00      0.99      6471\n",
      "        1.0       0.00      0.00      0.00        74\n",
      "\n",
      "avg / total       0.98      0.99      0.98      6545\n",
      "\n",
      "SHOPS\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        0.0       1.00      1.00      1.00      6515\n",
      "        1.0       0.00      0.00      0.00        30\n",
      "\n",
      "avg / total       0.99      1.00      0.99      6545\n",
      "\n",
      "AID_CENTERS\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.99      1.00      0.99      6464\n",
      "        1.0       0.00      0.00      0.00        81\n",
      "\n",
      "avg / total       0.98      0.99      0.98      6545\n",
      "\n",
      "OTHER_INFRASTRUCTURE\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.96      1.00      0.98      6297\n",
      "        1.0       0.00      0.00      0.00       248\n",
      "\n",
      "avg / total       0.93      0.96      0.94      6545\n",
      "\n",
      "WEATHER_RELATED\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.72      1.00      0.84      4745\n",
      "        1.0       0.00      0.00      0.00      1800\n",
      "\n",
      "avg / total       0.53      0.72      0.61      6545\n",
      "\n",
      "FLOODS\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.92      1.00      0.96      5994\n",
      "        1.0       0.00      0.00      0.00       551\n",
      "\n",
      "avg / total       0.84      0.92      0.88      6545\n",
      "\n",
      "STORM\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.91      1.00      0.95      5941\n",
      "        1.0       0.00      0.00      0.00       604\n",
      "\n",
      "avg / total       0.82      0.91      0.86      6545\n",
      "\n",
      "FIRE\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.99      1.00      0.99      6478\n",
      "        1.0       0.00      0.00      0.00        67\n",
      "\n",
      "avg / total       0.98      0.99      0.98      6545\n",
      "\n",
      "EARTHQUAKE\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.90      1.00      0.95      5911\n",
      "        1.0       0.00      0.00      0.00       634\n",
      "\n",
      "avg / total       0.82      0.90      0.86      6545\n",
      "\n",
      "COLD\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.98      1.00      0.99      6400\n",
      "        1.0       0.00      0.00      0.00       145\n",
      "\n",
      "avg / total       0.96      0.98      0.97      6545\n",
      "\n",
      "OTHER_WEATHER\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.95      1.00      0.98      6241\n",
      "        1.0       0.00      0.00      0.00       304\n",
      "\n",
      "avg / total       0.91      0.95      0.93      6545\n",
      "\n",
      "DIRECT_REPORT\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.81      1.00      0.90      5305\n",
      "        1.0       0.00      0.00      0.00      1240\n",
      "\n",
      "avg / total       0.66      0.81      0.73      6545\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "cv_preds = cv.predict(X_test)\n",
    "pred_cols = y_test.columns.tolist()\n",
    "for i,col in enumerate(pred_cols):\n",
    "     print(col.upper()+'\\n', classification_report(y_test[col].values, cv_preds[:,i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Try improving your model further. Here are a few ideas:\n",
    "* try other machine learning algorithms\n",
    "* add other features besides the TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. Export your model as a pickle file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle.dump(cv, open('rf_model.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10. Use this notebook to complete `train.py`\n",
    "Use the template file attached in the Resources folder to write a script that runs the steps above to create a database and export a model based on a new dataset specified by the user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
